{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1fb7213-5aa1-44e5-8863-4d4b15bfc62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+------------+------------+\n",
      "|passenger_count|pulocationid|dolocationid|total_amount|\n",
      "+---------------+------------+------------+------------+\n",
      "|            1.0|       151.0|       239.0|        9.95|\n",
      "|            1.0|       239.0|       246.0|        16.3|\n",
      "|            3.0|       236.0|       236.0|         5.8|\n",
      "|            5.0|       193.0|       193.0|        7.55|\n",
      "|            5.0|       193.0|       193.0|       55.55|\n",
      "|            5.0|       193.0|       193.0|       13.31|\n",
      "|            5.0|       193.0|       193.0|       55.55|\n",
      "|            1.0|       163.0|       229.0|        9.05|\n",
      "|            1.0|       229.0|         7.0|        18.5|\n",
      "|            2.0|       141.0|       234.0|        13.0|\n",
      "+---------------+------------+------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"a4\").getOrCreate()\n",
    "df = spark.read.csv(\"2019-01-h1.csv\", header=True, inferSchema=True)\n",
    "df.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\").show(10)\n",
    "\n",
    "# Creating trainDF and testDF\n",
    "trainDF, testDF = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc721e9-9dfc-4d5e-8d7f-deb3d7f23286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "# Combining input columns into a single features vector\n",
    "assembler = VectorAssembler(inputCols=[\"passenger_count\", \"pulocationid\", \"dolocationid\"], outputCol=\"features\")\n",
    "\n",
    "# Creating a Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"total_amount\")\n",
    "\n",
    "# Setting maxBins \n",
    "dt = dt.setMaxBins(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2b46e1-d74a-4aa4-833d-58570ccf0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Putting assembler and regressor into a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, dt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2b773e-f247-461d-9661-1d399a3338f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model using the training DataFrame\n",
    "model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e64cd36-6fa9-4e7d-be83-e31ad30e7422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+------------+------------+------------------+\n",
      "|passenger_count|pulocationid|dolocationid|total_amount|        prediction|\n",
      "+---------------+------------+------------+------------+------------------+\n",
      "|            1.0|       223.0|       223.0|         4.3| 12.02645461205501|\n",
      "|            1.0|       234.0|       186.0|         6.2| 12.02645461205501|\n",
      "|            1.0|       158.0|       249.0|         5.8| 12.02645461205501|\n",
      "|            1.0|       140.0|       237.0|        10.3| 12.02645461205501|\n",
      "|            1.0|       148.0|        79.0|         8.8|15.722258274971887|\n",
      "|            1.0|       233.0|       198.0|        27.3| 12.02645461205501|\n",
      "|            1.0|       158.0|       164.0|        14.8| 12.02645461205501|\n",
      "|            4.0|       161.0|       229.0|         6.8| 12.02645461205501|\n",
      "|            1.0|       143.0|       262.0|        15.3| 12.02645461205501|\n",
      "|            3.0|        37.0|        36.0|         7.3|  17.8758503968399|\n",
      "+---------------+------------+------------+------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test set\n",
    "predictions = model.transform(testDF)\n",
    "\n",
    "# Showing the features, total amount, and prediction\n",
    "predictions.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\", \"prediction\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea76249c-4425-4231-afc2-9271744334e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 48.54838873706549\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Setting up the evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "# Calculating RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb01766-69d4-48a3-831e-e2fd2a5b2b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
